name: Weekly Movie Scraper

# تشغيله أسبوعيًا أو يدويًا
on:
  schedule:
    - cron: "0 0 * * 0"   # كل أسبوع (الأحد 00:00 UTC)
  workflow_dispatch:      # لتشغيله يدويًا

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # للسماح بالكتابة على المستودع

    steps:
      # 1️⃣ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      # 2️⃣ Setup Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      # 3️⃣ Cache pip dependencies
      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 4️⃣ Install dependencies
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install requests beautifulsoup4

      # 5️⃣ Run scraper
      - name: Run scraper
        run: |
          python scraper.py || echo "Scraper failed with exit code $?"

      # 6️⃣ Commit & push movies.json if changed
      - name: Commit and Push changes
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git add movies.json
          if ! git diff --cached --quiet; then
            git commit -m "Update movies.json [skip ci]"
            git push
          else
            echo "No changes detected"
          fi
